{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3., -1., -1.,  1.,  4.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 5.4.1 不带参数的层\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class CenteredLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 3, 3, 5, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6298e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###5.4.2 带参数的层\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.1969, -0.9032,  0.0677],\n",
       "        [ 1.0362,  0.3927, -1.2357],\n",
       "        [ 2.0910,  1.5024, -1.3546],\n",
       "        [-0.7833,  0.6041,  0.3980],\n",
       "        [ 0.9324, -0.4150,  0.5066]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1284, 0.4850, 0.0000],\n",
       "        [0.1152, 0.9498, 0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [1.3918]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.设计一个接受输入并计算张量降维的层，它返回$y_k = \\sum_{i, j} W_{ijk} x_i x_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.6070,   4.3160,   2.0065],\n",
      "        [ -5.9531,   6.0379,  11.3702],\n",
      "        [ -1.4948,  -2.2645,  -0.0199],\n",
      "        [-10.7556,  -0.4294,   3.4145],\n",
      "        [  0.1287,  -0.1465,   0.3475]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TensorReductionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TensorReductionLayer, self).__init__()\n",
    "        # 初始化权重张量 W，形状为 (output_dim, input_dim, input_dim)\n",
    "        self.W = nn.Parameter(torch.randn(output_dim, input_dim, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, input_dim)\n",
    "        batch_size, input_dim = x.size()\n",
    "        # 计算 y_k = sum_{i, j} W_{ijk} x_i x_j\n",
    "        y = torch.einsum('bij,bj->bi', torch.einsum('ijk,bj->bik', self.W, x), x)\n",
    "        return y\n",
    "\n",
    "# 示例用法\n",
    "input_dim = 4\n",
    "output_dim = 3\n",
    "layer = TensorReductionLayer(input_dim, output_dim)\n",
    "x = torch.randn(5, input_dim)  # 假设 batch_size 为 5\n",
    "y = layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.设计一个返回输入数据的傅立叶系数前半部分的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7904+0.0000j,  3.2212-1.2828j,  1.9614-2.3039j,  0.4601+1.5165j],\n",
      "        [ 1.4940+0.0000j, -0.9626-0.9018j, -1.8763+1.9419j, -0.2853+1.0206j],\n",
      "        [ 2.0841+0.0000j, -0.2409-1.0400j,  0.3734-2.3279j,  1.0405-3.3100j],\n",
      "        [ 1.6647+0.0000j,  0.7294+2.2995j,  0.4377+4.2767j, -0.6177+0.6312j],\n",
      "        [-1.2008+0.0000j, -0.2110-3.3579j,  2.3750-2.1237j, -3.1509-2.1700j]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FourierTransformLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FourierTransformLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算傅立叶变换\n",
    "        x_fft = torch.fft.fft(x, dim=-1)\n",
    "        # 只取前半部分系数\n",
    "        x_fft_half = x_fft[..., :x_fft.size(-1) // 2]\n",
    "        return x_fft_half\n",
    "\n",
    "# 示例用法\n",
    "layer = FourierTransformLayer()\n",
    "x = torch.randn(5, 8)  # 假设输入形状为 (batch_size, input_dim)\n",
    "y = layer(x)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
